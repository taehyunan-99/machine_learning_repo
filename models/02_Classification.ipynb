{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f20e0193",
   "metadata": {},
   "source": [
    "# 02. 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67a9656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# 로지스틱 회귀\n",
    "from torch.autograd import Variable\n",
    "# 다항분류\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acf01b2",
   "metadata": {},
   "source": [
    "## 2-1. 로지스틱 회귀\n",
    "### 이진 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cddbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 입출력 정의\n",
    "np.random.seed(42) # 시드 고정\n",
    "num_samples = 1000\n",
    "\n",
    "# 평균 및 공분산 설정\n",
    "mean_1 = np.array([1., 1.])\n",
    "cov_1 = np.array([[1,0], [0,1]])\n",
    "mean_2 = np.array([-1., -1.])\n",
    "cov_2 = np.array([[1,0], [0,1]])\n",
    "\n",
    "# 데이터 생성\n",
    "# multivariate_normal(평균, 공분산, 점의 수)\n",
    "data_1 = np.random.multivariate_normal(mean_1, cov_1, num_samples // 2)\n",
    "data_2 = np.random.multivariate_normal(mean_2, cov_2, num_samples // 2)\n",
    "\n",
    "# 데이터 확인\n",
    "plt.scatter(data_1[:, 0], data_1[:, 1], color=\"b\", label=\"Class1\")\n",
    "plt.scatter(data_2[:, 0], data_2[:, 1], color=\"r\", label=\"Class0\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 데이터 정의 및 텐서로 변환\n",
    "data = np.vstack((data_1, data_2))\n",
    "labels = np.ones(num_samples)\n",
    "labels[num_samples // 2:] = 0\n",
    "\n",
    "data = torch.from_numpy(data).float()\n",
    "labels = torch.from_numpy(labels).float()\n",
    "labels = labels.view(-1, 1)\n",
    "num_samples, num_features = data.shape\n",
    "\n",
    "# 2. 모델 정의\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "model = LogisticRegression(2, 1)\n",
    "\n",
    "# 3. 손실함수 정의\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# 4. 가중치 업데이트(학습)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "epochs = 1000\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    inputs = Variable(data)\n",
    "    targets = Variable(labels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1} / {epochs}], Loss : {loss.item(): .4f}\")\n",
    "\n",
    "# 5. 시각화\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 결정 경계 그리기\n",
    "w = model.linear.weight.data.numpy()\n",
    "b = model.linear.bias.data.numpy()\n",
    "x_plot = np.array([-2,2])\n",
    "y_plot = (-b - w[0][0] * x_plot / w[0][1]) # 결정 경계 함수\n",
    "plt.plot(x_plot, y_plot, color=\"g\", label=\"Decision Boundary\")\n",
    "plt.scatter(data_1[:, 0], data_1[:, 1], color=\"b\", label=\"Class1\")\n",
    "plt.scatter(data_2[:, 0], data_2[:, 1], color=\"r\", label=\"Class0\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3c8506",
   "metadata": {},
   "source": [
    "## 2-2. FashionMNIST 신경망 (다항분류)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5d72e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 입출력 정의\n",
    "transform = transforms.ToTensor() # 이미지 데이터를 Tensor로 변환\n",
    "\n",
    "# 트레이닝 테이터 정의\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# 테스트 데이터 정의\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# 데이터 로더 정의\n",
    "batch_size = 64 # 미니 배치 경사 하강법\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 2. 모델 정의\n",
    "class MultiClassificationModeel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "\n",
    "model = MultiClassificationModeel()\n",
    "\n",
    "# 3. 손실함수 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 4. 가중치 업데이트\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "epochs = 10\n",
    "\n",
    "# 학습 루프\n",
    "def train_loop(dataloader, model, criterion, optimizer):\n",
    "    model.train() # 학습 모드\n",
    "    size = len(dataloader.dataset)\n",
    "    running_loss = 0.\n",
    "\n",
    "    # x = 데이터 y = 정답 batch = idx\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        optimizer.zero_grad() # 초기화\n",
    "        outputs = model(x) # 순전파\n",
    "        loss = criterion(outputs, y) # 손실 계산\n",
    "        loss.backward() # 역전파\n",
    "        optimizer.step() # 가중치 업데이트\n",
    "\n",
    "        running_loss += loss.item() * x.size(0) # loss에 batch size를 곱함\n",
    "\n",
    "        if (batch+1) % 100 == 0:\n",
    "            current = batch * len(x)\n",
    "            print(f\"[batch : {batch+1: 4d}], Loss : {loss.item():>7f} ({current:>5d} / {size:>5d})\")\n",
    "    \n",
    "    epoch_loss = running_loss / size\n",
    "    return epoch_loss\n",
    "\n",
    "# 테스트 루프\n",
    "def test_loop(dataloader, model, criterion):\n",
    "    model.eval() # 평가 모드\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0.\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            test_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == y).sum().item()\n",
    "\n",
    "    avg_loss = test_loss / num_batches\n",
    "    accuracy = correct / size\n",
    "    print(f\"Test - Accuracy : {100*accuracy:>5.1f}%, Avg_loss : {avg_loss:>8f}\")\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# 학습 실행\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n[Epoch] {epoch+1} / {epochs}\")\n",
    "    train_loss = train_loop(train_dataloader, model, criterion, optimizer)\n",
    "    val_loss, val_acc = test_loop(test_dataloader, model, criterion)\n",
    "\n",
    "print(\"\\n완료!\")\n",
    "\n",
    "# 5. 시각화\n",
    "label_tags = {\n",
    "    0: \"T-Shirt\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\", 5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle Boot\"\n",
    "}\n",
    "\n",
    "rows, columns = 6, 6\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "model.eval()\n",
    "\n",
    "for i in range(1, rows * columns + 1):\n",
    "    data_idx = np.random.randint(len(test_data))\n",
    "    img_tensor, trus_label = test_data[data_idx]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x = img_tensor.unsqueeze(0) # 데이터 변형\n",
    "        output = model(x)\n",
    "        pred_idx = output.argmax(1).item()\n",
    "\n",
    "    pred_class = label_tags[pred_idx] # 예측한 태그\n",
    "    true_class = label_tags[trus_label] # 정답 태그\n",
    "\n",
    "    is_correct = (pred_idx == int(trus_label))\n",
    "    title = f\"{pred_class}, Correct!\" if is_correct else f\"{pred_class}, Incorrect! answer : {true_class}\"\n",
    "    cmap = \"Blues\" if is_correct else \"Reds\"\n",
    "\n",
    "    ax = fig.add_subplot(rows, columns, i)\n",
    "    ax.imshow(img_tensor.squeeze(0).numpy(), cmap=cmap)\n",
    "    ax.set_title(title, fontsize=10)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
